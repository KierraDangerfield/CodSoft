{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"100F1T-ixEB0Ug45BxJi2ZEezF2QLqyIq","authorship_tag":"ABX9TyP1uYs/wepgcP0WofECBJQ3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Simple Chatbot\n"],"metadata":{"id":"Hnz4UGojVEv6"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U65cZQp9UxIK","executionInfo":{"status":"ok","timestamp":1698939416606,"user_tz":300,"elapsed":782,"user":{"displayName":"Kierra Dangerfield","userId":"13136364548471438380"}},"outputId":"d3f55381-c624-40c1-c0de-d954b2b584b8"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":41}],"source":["#Imports\n","import json\n","import string\n","import random\n","import nltk\n","import numpy as num\n","from nltk.stem import WordNetLemmatizer\n","import tensorflow as tf\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","\n","# required package for tokenization\n","nltk.download(\"punkt\")\n","# word database\n","nltk.download(\"wordnet\")"]},{"cell_type":"code","source":["data = {\"intents\": [\n","\n","             {\"tag\": \"age\",\n","              \"patterns\": [\"how old are you?\"],\n","              \"responses\": [\"I am 28 years old.\", \"I was born on October 7th 1995.\", \"My Birthday is October 7th 1995.\"],\n","             },\n","              {\"tag\": \"greeting\",\n","              \"patterns\": [ \"Hi\", \"Hello\", \"Hey\", \"Hi There\"],\n","              \"responses\": [\"Hi there\", \"Hello\", \"Hi :)\"],\n","             },\n","              {\"tag\": \"goodbye\",\n","              \"patterns\": [ \"bye\", \"later\"],\n","              \"responses\": [\"Bye\", \"take care\"]\n","             },\n","             {\"tag\": \"name\",\n","              \"patterns\": [\"what's your name?\", \"Who are you?\"],\n","              \"responses\": [\"My name is Kierra,\" ,\"Kierra is my name.\"]\n","             },\n","             {\"tag\": \"conversation\",\n","              \"patterns\": [\"How are you?\", \"How you been\"],\n","              \"responses\": [\"I am good,\" ,\"Great\", \"I've been better.\"]\n","             }\n","\n","]}"],"metadata":{"id":"vqD81xn3VYEV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preprocess Data"],"metadata":{"id":"4IuQPLdjh2AR"}},{"cell_type":"code","source":["lm = WordNetLemmatizer() #for getting words\n","\n","# lists\n","classes = []\n","words = []\n","documentX = []\n","documentY = []\n","\n","#Loop through Intents\n","for intent in data[\"intents\"]:\n","    for pattern in intent[\"patterns\"]:\n","\n","        # tokenize the patterns\n","        ournewTkns = nltk.word_tokenize(pattern)\n","\n","        # extends the tokens\n","        words.extend(ournewTkns)\n","\n","        documentX.append(pattern)\n","        documentY.append(intent[\"tag\"])\n","\n","    # add unexisting tags to their respective classes\n","    if intent[\"tag\"] not in classes:\n","        classes.append(intent[\"tag\"])\n","\n","# set words to lowercase if not in punctuation\n","words = [lm.lemmatize(word.lower()) for word in words if word not in string.punctuation]\n","\n","# sort words\n","words = sorted(set(words))\n","\n","# sort classes\n","classes = sorted(set(classes))"],"metadata":{"id":"6IbARTKrU0cK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLPfSD8pWQ21","executionInfo":{"status":"ok","timestamp":1698939416825,"user_tz":300,"elapsed":21,"user":{"displayName":"Kierra Dangerfield","userId":"13136364548471438380"}},"outputId":"5c274b9a-1757-44f9-f175-a643a5d8a89d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[\"'s\", 'are', 'been', 'bye', 'hello', 'hey', 'hi', 'how', 'later', 'name', 'old', 'there', 'what', 'who', 'you', 'your']\n"]}]},{"cell_type":"code","source":["print(classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XK0761HUWZAB","executionInfo":{"status":"ok","timestamp":1698939416825,"user_tz":300,"elapsed":19,"user":{"displayName":"Kierra Dangerfield","userId":"13136364548471438380"}},"outputId":"41fd1ac0-71e3-4be9-9a7d-2da0b0c76b6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['age', 'conversation', 'goodbye', 'greeting', 'name']\n"]}]},{"cell_type":"code","source":["print(documentX)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MiwBRQ2WcRz","executionInfo":{"status":"ok","timestamp":1698939416826,"user_tz":300,"elapsed":18,"user":{"displayName":"Kierra Dangerfield","userId":"13136364548471438380"}},"outputId":"c4eb895d-8585-4bd0-b4fe-907002d7e18d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['how old are you?', 'Hi', 'Hello', 'Hey', 'Hi There', 'bye', 'later', \"what's your name?\", 'who are you?', 'How are you?', 'How you been']\n"]}]},{"cell_type":"code","source":["print(documentY)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3uAvpVTeWgK4","executionInfo":{"status":"ok","timestamp":1698939416826,"user_tz":300,"elapsed":16,"user":{"displayName":"Kierra Dangerfield","userId":"13136364548471438380"}},"outputId":"31492c5f-4189-4d2a-8e52-511ace8f5752"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['age', 'greeting', 'greeting', 'greeting', 'greeting', 'goodbye', 'goodbye', 'name', 'name', 'conversation', 'conversation']\n"]}]},{"cell_type":"markdown","source":["# Design Neural network\n","\n","Converting to numerical data"],"metadata":{"id":"IAewptNZXeCM"}},{"cell_type":"code","source":["# training list array\n","trainingData = []\n","outEmpty = [0] * len(classes)\n","\n","# bow model\n","for idx, doc in enumerate(documentX):\n","    bagOfwords = []\n","    text = lm.lemmatize(doc.lower())\n","    for word in words:\n","        bagOfwords.append(1) if word in text else bagOfwords.append(0)\n","\n","    outputRow = list(outEmpty)\n","    outputRow[classes.index(documentY[idx])] = 1\n","    trainingData.append([bagOfwords, outputRow])\n","\n","random.shuffle(trainingData)\n","# convert data into an array after shuffling\n","trainingData = num.array(trainingData, dtype=object)\n","\n","#input\n","x = num.array(list(trainingData[:, 0]))\n","#output\n","y = num.array(list(trainingData[:, 1]))"],"metadata":{"id":"RdAu_P4MWiN_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"EzWDaNGiX_ou"}},{"cell_type":"code","source":["inputShape = (len(x[0]),)\n","outputShape = len(y[0])\n","\n","# model\n","model = Sequential()\n","\n","# Dense function adds an output layer\n","model.add(Dense(128, input_shape=inputShape, activation=\"relu\"))\n","\n","model.add(Dropout(0.5))\n","# Dropout is used to enhance visual perception of input neurons\n","\n","model.add(Dense(64, activation=\"relu\"))\n","model.add(Dropout(0.3))\n","model.add(Dense(outputShape, activation = \"softmax\"))\n","\n","md = tf.keras.optimizers.Adam(learning_rate=0.01, weight_decay=1e-6)\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=md,\n","              metrics=[\"accuracy\"])\n","\n","# Output the model in summary\n","print(model.summary())\n","\n","\n","model.fit(x, y, epochs=200, verbose=1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"buLbg1x9jZZ7","executionInfo":{"status":"ok","timestamp":1698939420571,"user_tz":300,"elapsed":3759,"user":{"displayName":"Kierra Dangerfield","userId":"13136364548471438380"}},"outputId":"efd722ca-06e4-4b35-eaca-2ec83c3330ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_15 (Dense)            (None, 128)               2176      \n","                                                                 \n"," dropout_10 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_16 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_11 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_17 (Dense)            (None, 5)                 325       \n","                                                                 \n","=================================================================\n","Total params: 10757 (42.02 KB)\n","Trainable params: 10757 (42.02 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Epoch 1/200\n","1/1 [==============================] - 1s 855ms/step - loss: 1.7443 - accuracy: 0.0909\n","Epoch 2/200\n","1/1 [==============================] - 0s 19ms/step - loss: 1.5444 - accuracy: 0.2727\n","Epoch 3/200\n","1/1 [==============================] - 0s 14ms/step - loss: 1.5021 - accuracy: 0.3636\n","Epoch 4/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.3578 - accuracy: 0.5455\n","Epoch 5/200\n","1/1 [==============================] - 0s 12ms/step - loss: 1.2707 - accuracy: 0.8182\n","Epoch 6/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.1994 - accuracy: 0.6364\n","Epoch 7/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0604 - accuracy: 0.7273\n","Epoch 8/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.8821 - accuracy: 0.8182\n","Epoch 9/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.9369 - accuracy: 0.8182\n","Epoch 10/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.8847 - accuracy: 0.7273\n","Epoch 11/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.7457 - accuracy: 0.6364\n","Epoch 12/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6013 - accuracy: 0.8182\n","Epoch 13/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.6287 - accuracy: 0.8182\n","Epoch 14/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.4812 - accuracy: 0.7273\n","Epoch 15/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.3642 - accuracy: 0.9091\n","Epoch 16/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.3190 - accuracy: 0.9091\n","Epoch 17/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.3702 - accuracy: 0.9091\n","Epoch 18/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.3466 - accuracy: 0.8182\n","Epoch 19/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.2100 - accuracy: 0.9091\n","Epoch 20/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.1098 - accuracy: 1.0000\n","Epoch 21/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.1011 - accuracy: 1.0000\n","Epoch 22/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.1035 - accuracy: 1.0000\n","Epoch 23/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0924 - accuracy: 1.0000\n","Epoch 24/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0629 - accuracy: 1.0000\n","Epoch 25/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.1856 - accuracy: 0.9091\n","Epoch 26/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0486 - accuracy: 1.0000\n","Epoch 27/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0531 - accuracy: 1.0000\n","Epoch 28/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.3116 - accuracy: 0.8182\n","Epoch 29/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0356 - accuracy: 1.0000\n","Epoch 30/200\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0290 - accuracy: 1.0000\n","Epoch 31/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 32/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 1.0000\n","Epoch 33/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.1315 - accuracy: 0.9091\n","Epoch 34/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 1.0000\n","Epoch 35/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 1.0000\n","Epoch 36/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0111 - accuracy: 1.0000\n","Epoch 37/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0102 - accuracy: 1.0000\n","Epoch 38/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0716 - accuracy: 0.9091\n","Epoch 39/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 40/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2044 - accuracy: 0.9091\n","Epoch 41/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 42/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 1.0000\n","Epoch 43/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.1706 - accuracy: 0.9091\n","Epoch 44/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 45/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0197 - accuracy: 1.0000\n","Epoch 46/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 1.0000\n","Epoch 47/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000\n","Epoch 48/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0093 - accuracy: 1.0000\n","Epoch 49/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0195 - accuracy: 1.0000\n","Epoch 50/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0071 - accuracy: 1.0000\n","Epoch 51/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0499 - accuracy: 1.0000\n","Epoch 52/200\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0111 - accuracy: 1.0000\n","Epoch 53/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0044 - accuracy: 1.0000\n","Epoch 54/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 1.0000\n","Epoch 55/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 1.0000\n","Epoch 56/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 57/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0878 - accuracy: 0.9091\n","Epoch 58/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0364 - accuracy: 1.0000\n","Epoch 59/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0088 - accuracy: 1.0000\n","Epoch 60/200\n","1/1 [==============================] - 0s 10ms/step - loss: 7.4103e-04 - accuracy: 1.0000\n","Epoch 61/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0369 - accuracy: 1.0000\n","Epoch 62/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 63/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 64/200\n","1/1 [==============================] - 0s 11ms/step - loss: 8.4449e-04 - accuracy: 1.0000\n","Epoch 65/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 66/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 67/200\n","1/1 [==============================] - 0s 10ms/step - loss: 7.3679e-04 - accuracy: 1.0000\n","Epoch 68/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0522 - accuracy: 1.0000\n","Epoch 69/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.1066 - accuracy: 0.9091\n","Epoch 70/200\n","1/1 [==============================] - 0s 8ms/step - loss: 3.8815e-04 - accuracy: 1.0000\n","Epoch 71/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 72/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 73/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 74/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0125 - accuracy: 1.0000\n","Epoch 75/200\n","1/1 [==============================] - 0s 10ms/step - loss: 7.6234e-05 - accuracy: 1.0000\n","Epoch 76/200\n","1/1 [==============================] - 0s 10ms/step - loss: 3.4561e-04 - accuracy: 1.0000\n","Epoch 77/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.5180e-04 - accuracy: 1.0000\n","Epoch 78/200\n","1/1 [==============================] - 0s 10ms/step - loss: 9.8498e-04 - accuracy: 1.0000\n","Epoch 79/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 1.0000\n","Epoch 80/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.2074e-04 - accuracy: 1.0000\n","Epoch 81/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.4539e-04 - accuracy: 1.0000\n","Epoch 82/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 83/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.2506 - accuracy: 0.9091\n","Epoch 84/200\n","1/1 [==============================] - 0s 11ms/step - loss: 5.7244e-04 - accuracy: 1.0000\n","Epoch 85/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0079 - accuracy: 1.0000\n","Epoch 86/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 1.0000\n","Epoch 87/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 1.0000\n","Epoch 88/200\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 89/200\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 1.0000\n","Epoch 90/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0432 - accuracy: 1.0000\n","Epoch 91/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 1.0000\n","Epoch 92/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.7977e-04 - accuracy: 1.0000\n","Epoch 93/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.1941e-04 - accuracy: 1.0000\n","Epoch 94/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0201 - accuracy: 1.0000\n","Epoch 95/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 96/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 97/200\n","1/1 [==============================] - 0s 9ms/step - loss: 4.9224e-04 - accuracy: 1.0000\n","Epoch 98/200\n","1/1 [==============================] - 0s 9ms/step - loss: 2.9728e-04 - accuracy: 1.0000\n","Epoch 99/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 100/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0753 - accuracy: 0.9091\n","Epoch 101/200\n","1/1 [==============================] - 0s 9ms/step - loss: 5.9736e-04 - accuracy: 1.0000\n","Epoch 102/200\n","1/1 [==============================] - 0s 10ms/step - loss: 3.2563e-04 - accuracy: 1.0000\n","Epoch 103/200\n","1/1 [==============================] - 0s 10ms/step - loss: 5.4717e-04 - accuracy: 1.0000\n","Epoch 104/200\n","1/1 [==============================] - 0s 10ms/step - loss: 4.3151e-04 - accuracy: 1.0000\n","Epoch 105/200\n","1/1 [==============================] - 0s 9ms/step - loss: 4.3616e-05 - accuracy: 1.0000\n","Epoch 106/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 107/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 1.0000\n","Epoch 108/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 109/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.6656e-04 - accuracy: 1.0000\n","Epoch 110/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 111/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0039 - accuracy: 1.0000\n","Epoch 112/200\n","1/1 [==============================] - 0s 10ms/step - loss: 5.0116e-04 - accuracy: 1.0000\n","Epoch 113/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.5122e-04 - accuracy: 1.0000\n","Epoch 114/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 115/200\n","1/1 [==============================] - 0s 11ms/step - loss: 3.7854e-04 - accuracy: 1.0000\n","Epoch 116/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0071 - accuracy: 1.0000\n","Epoch 117/200\n","1/1 [==============================] - 0s 10ms/step - loss: 8.9231e-05 - accuracy: 1.0000\n","Epoch 118/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.1215e-04 - accuracy: 1.0000\n","Epoch 119/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 1.0000\n","Epoch 120/200\n","1/1 [==============================] - 0s 10ms/step - loss: 4.3557e-04 - accuracy: 1.0000\n","Epoch 121/200\n","1/1 [==============================] - 0s 9ms/step - loss: 4.3259e-05 - accuracy: 1.0000\n","Epoch 122/200\n","1/1 [==============================] - 0s 9ms/step - loss: 7.4475e-04 - accuracy: 1.0000\n","Epoch 123/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 124/200\n","1/1 [==============================] - 0s 10ms/step - loss: 5.3777e-04 - accuracy: 1.0000\n","Epoch 125/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.3139e-04 - accuracy: 1.0000\n","Epoch 126/200\n","1/1 [==============================] - 0s 10ms/step - loss: 4.4976e-04 - accuracy: 1.0000\n","Epoch 127/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 128/200\n","1/1 [==============================] - 0s 11ms/step - loss: 2.0528e-04 - accuracy: 1.0000\n","Epoch 129/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.2590e-04 - accuracy: 1.0000\n","Epoch 130/200\n","1/1 [==============================] - 0s 10ms/step - loss: 4.4883e-04 - accuracy: 1.0000\n","Epoch 131/200\n","1/1 [==============================] - 0s 10ms/step - loss: 3.9383e-04 - accuracy: 1.0000\n","Epoch 132/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 133/200\n","1/1 [==============================] - 0s 12ms/step - loss: 9.1981e-05 - accuracy: 1.0000\n","Epoch 134/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0056 - accuracy: 1.0000\n","Epoch 135/200\n","1/1 [==============================] - 0s 10ms/step - loss: 7.8578e-05 - accuracy: 1.0000\n","Epoch 136/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.0757e-04 - accuracy: 1.0000\n","Epoch 137/200\n","1/1 [==============================] - 0s 10ms/step - loss: 8.1801e-04 - accuracy: 1.0000\n","Epoch 138/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 139/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.0972e-04 - accuracy: 1.0000\n","Epoch 140/200\n","1/1 [==============================] - 0s 10ms/step - loss: 7.1053e-04 - accuracy: 1.0000\n","Epoch 141/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.1047e-04 - accuracy: 1.0000\n","Epoch 142/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.1416e-04 - accuracy: 1.0000\n","Epoch 143/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0057 - accuracy: 1.0000\n","Epoch 144/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.2061e-05 - accuracy: 1.0000\n","Epoch 145/200\n","1/1 [==============================] - 0s 10ms/step - loss: 6.1069e-04 - accuracy: 1.0000\n","Epoch 146/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 147/200\n","1/1 [==============================] - 0s 13ms/step - loss: 1.3695e-04 - accuracy: 1.0000\n","Epoch 148/200\n","1/1 [==============================] - 0s 11ms/step - loss: 2.2623e-04 - accuracy: 1.0000\n","Epoch 149/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.5017e-04 - accuracy: 1.0000\n","Epoch 150/200\n","1/1 [==============================] - 0s 14ms/step - loss: 8.5378e-04 - accuracy: 1.0000\n","Epoch 151/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.1631e-04 - accuracy: 1.0000\n","Epoch 152/200\n","1/1 [==============================] - 0s 11ms/step - loss: 3.5959e-04 - accuracy: 1.0000\n","Epoch 153/200\n","1/1 [==============================] - 0s 11ms/step - loss: 3.1157e-04 - accuracy: 1.0000\n","Epoch 154/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.2594e-04 - accuracy: 1.0000\n","Epoch 155/200\n","1/1 [==============================] - 0s 10ms/step - loss: 7.0657e-06 - accuracy: 1.0000\n","Epoch 156/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.3360e-04 - accuracy: 1.0000\n","Epoch 157/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 158/200\n","1/1 [==============================] - 0s 11ms/step - loss: 4.1315e-05 - accuracy: 1.0000\n","Epoch 159/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 1.0000\n","Epoch 160/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 161/200\n","1/1 [==============================] - 0s 11ms/step - loss: 2.0298e-04 - accuracy: 1.0000\n","Epoch 162/200\n","1/1 [==============================] - 0s 11ms/step - loss: 2.5585e-05 - accuracy: 1.0000\n","Epoch 163/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 164/200\n","1/1 [==============================] - 0s 14ms/step - loss: 4.5599e-04 - accuracy: 1.0000\n","Epoch 165/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.5940e-04 - accuracy: 1.0000\n","Epoch 166/200\n","1/1 [==============================] - 0s 10ms/step - loss: 3.7545e-05 - accuracy: 1.0000\n","Epoch 167/200\n","1/1 [==============================] - 0s 11ms/step - loss: 3.5816e-04 - accuracy: 1.0000\n","Epoch 168/200\n","1/1 [==============================] - 0s 10ms/step - loss: 5.7654e-04 - accuracy: 1.0000\n","Epoch 169/200\n","1/1 [==============================] - 0s 10ms/step - loss: 5.2334e-04 - accuracy: 1.0000\n","Epoch 170/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0095 - accuracy: 1.0000\n","Epoch 171/200\n","1/1 [==============================] - 0s 11ms/step - loss: 2.1748e-04 - accuracy: 1.0000\n","Epoch 172/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 1.0000\n","Epoch 173/200\n","1/1 [==============================] - 0s 11ms/step - loss: 6.0646e-05 - accuracy: 1.0000\n","Epoch 174/200\n","1/1 [==============================] - 0s 11ms/step - loss: 5.0948e-05 - accuracy: 1.0000\n","Epoch 175/200\n","1/1 [==============================] - 0s 10ms/step - loss: 6.6846e-05 - accuracy: 1.0000\n","Epoch 176/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.6428e-05 - accuracy: 1.0000\n","Epoch 177/200\n","1/1 [==============================] - 0s 10ms/step - loss: 3.2189e-04 - accuracy: 1.0000\n","Epoch 178/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.4551e-04 - accuracy: 1.0000\n","Epoch 179/200\n","1/1 [==============================] - 0s 12ms/step - loss: 5.5219e-05 - accuracy: 1.0000\n","Epoch 180/200\n","1/1 [==============================] - 0s 10ms/step - loss: 7.9706e-04 - accuracy: 1.0000\n","Epoch 181/200\n","1/1 [==============================] - 0s 11ms/step - loss: 4.9531e-05 - accuracy: 1.0000\n","Epoch 182/200\n","1/1 [==============================] - 0s 10ms/step - loss: 3.9325e-05 - accuracy: 1.0000\n","Epoch 183/200\n","1/1 [==============================] - 0s 11ms/step - loss: 2.3418e-05 - accuracy: 1.0000\n","Epoch 184/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0033 - accuracy: 1.0000\n","Epoch 185/200\n","1/1 [==============================] - 0s 11ms/step - loss: 5.9046e-04 - accuracy: 1.0000\n","Epoch 186/200\n","1/1 [==============================] - 0s 11ms/step - loss: 8.4632e-04 - accuracy: 1.0000\n","Epoch 187/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0033 - accuracy: 1.0000\n","Epoch 188/200\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0021e-04 - accuracy: 1.0000\n","Epoch 189/200\n","1/1 [==============================] - 0s 11ms/step - loss: 2.6983e-05 - accuracy: 1.0000\n","Epoch 190/200\n","1/1 [==============================] - 0s 11ms/step - loss: 3.4687e-05 - accuracy: 1.0000\n","Epoch 191/200\n","1/1 [==============================] - 0s 13ms/step - loss: 4.0859e-04 - accuracy: 1.0000\n","Epoch 192/200\n","1/1 [==============================] - 0s 11ms/step - loss: 9.7339e-04 - accuracy: 1.0000\n","Epoch 193/200\n","1/1 [==============================] - 0s 11ms/step - loss: 8.6130e-05 - accuracy: 1.0000\n","Epoch 194/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 195/200\n","1/1 [==============================] - 0s 10ms/step - loss: 5.4937e-05 - accuracy: 1.0000\n","Epoch 196/200\n","1/1 [==============================] - 0s 10ms/step - loss: 3.6400e-04 - accuracy: 1.0000\n","Epoch 197/200\n","1/1 [==============================] - 0s 11ms/step - loss: 2.2399e-05 - accuracy: 1.0000\n","Epoch 198/200\n","1/1 [==============================] - 0s 10ms/step - loss: 7.5713e-05 - accuracy: 1.0000\n","Epoch 199/200\n","1/1 [==============================] - 0s 11ms/step - loss: 2.5531e-05 - accuracy: 1.0000\n","Epoch 200/200\n","1/1 [==============================] - 0s 10ms/step - loss: 3.2753e-04 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x79a792e49f90>"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["# Add Features"],"metadata":{"id":"PmFRQoA3lG88"}},{"cell_type":"code","source":["def wordText(text):\n","  newtkns = nltk.word_tokenize(text)\n","  newtkns = [lm.lemmatize(word) for word in newtkns]\n","  return newtkns\n","\n","def wordBag(text, vocab):\n","  newtkns = wordText(text)\n","  bagOwords = [0] * len(vocab)\n","  for w in newtkns:\n","    for idx, word in enumerate(vocab):\n","      if word == w:\n","        bagOwords[idx] = 1\n","  return num.array(bagOwords)\n","\n","def Pclass(text, vocab, labels):\n","  bagOwords = wordBag(text, vocab)\n","  ourResult = model.predict(num.array([bagOwords]))[0]\n","  newThresh = 0.2\n","  yp = [[idx, res] for idx, res in enumerate(ourResult) if res > newThresh]\n","\n","  yp.sort(key=lambda x: x[1], reverse=True)\n","  newList = []\n","  for r in yp:\n","    newList.append(labels[r[0]])\n","  return newList\n","\n","def getRes(firstlist, fJson):\n","  tag = firstlist[0]\n","  listOfIntents = fJson[\"intents\"]\n","  for i in listOfIntents:\n","    if i[\"tag\"] == tag:\n","      ourResult = random.choice(i[\"responses\"])\n","      break\n","  return ourResult"],"metadata":{"id":"dW2SRjC2YETb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# running the chatbot\n","while True:\n","    newMessage = input(\"\")\n","    intents = Pclass(newMessage, words, classes)\n","    ourResult = getRes(intents, data)\n","    print(ourResult)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":704},"id":"yPQSdsEgZRN7","executionInfo":{"status":"error","timestamp":1698939504165,"user_tz":300,"elapsed":83599,"user":{"displayName":"Kierra Dangerfield","userId":"13136364548471438380"}},"outputId":"395a18ab-bc8c-45bb-d61c-880029963eed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hi\n","1/1 [==============================] - 0s 64ms/step\n","Hi there\n","How are you\n","1/1 [==============================] - 0s 21ms/step\n","Kierra is my name.\n","what is your nam\n","1/1 [==============================] - 0s 19ms/step\n","Kierra is my name.\n","How are you?\n","1/1 [==============================] - 0s 20ms/step\n","Kierra is my name.\n","bye\n","1/1 [==============================] - 0s 20ms/step\n","take care\n","exit\n","1/1 [==============================] - 0s 20ms/step\n","Hi there\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-7f5ec290180c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# running the chatbot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnewMessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mintents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mourResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetRes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]},{"cell_type":"markdown","source":["The next step is to use a library to make it more dynamic."],"metadata":{"id":"AYBQpzEpVKMb"}},{"cell_type":"code","source":[],"metadata":{"id":"16T4ddCHZWHk"},"execution_count":null,"outputs":[]}]}